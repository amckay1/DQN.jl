{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Gym\n",
    "using TensorFlow\n",
    "using Distributions\n",
    "include(\"utils.jl\");\n",
    "include(\"ReplayMemory.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA = 0.001 # learning rate\n",
    "GAMMA = 0.99 # decay rate of past observations\n",
    "OBSERVE = 100. # timesteps to observe before training\n",
    "EXPLORE = 500. # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.05 # final value of epsilon\n",
    "INITIAL_EPSILON = 1.0 # starting value of epsilon\n",
    "REPLAY_MEM_SIZE = 590000 # number of previous transitions to remember\n",
    "BATCHSIZE = 32 # size of minibatch\n",
    "K = 1 # only select an action every Kth frame, repeat prev for others\n",
    "TARGET_UPDATE_FREQ = 10 # update frequency for weights of target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL_STATE = reset(env) = [-0.0483421,-0.038216,0.0310807,-0.028438]\n",
      "ACTIONS = n_actions(env) = 2\n",
      "STATE_DIMS = (obs_dimensions(env))[1] = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:54:45,118] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "done = false\n",
    "r_tot = 0.0\n",
    "nsteps = 10\n",
    "\n",
    "obs = 0\n",
    "\n",
    "env = GymEnvironment(\"CartPole-v0\")\n",
    "@show INITIAL_STATE = reset(env)\n",
    "@show ACTIONS = n_actions(env)         # number of valid actions                                           \n",
    "@show STATE_DIMS = obs_dimensions(env)[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition createNetwork(Any, Any) in module Main at In[4]:3 overwritten at In[32]:3.\n",
      "WARNING: Method definition createNetwork(Any, Any, Any) in module Main at In[4]:3 overwritten at In[32]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "createNetwork (generic function with 2 methods)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createNetwork(ACTIONS, input_dim, hidden_dim=2)\n",
    "    # network weights\n",
    "    W1 = weight_variable([input_dim, hidden_dim])\n",
    "    b1 = bias_variable([hidden_dim])\n",
    "    \n",
    "    W2 = weight_variable([hidden_dim, ACTIONS])\n",
    "    b2 = bias_variable([ACTIONS])\n",
    "\n",
    "    # input layer\n",
    "    s = placeholder(Float32, shape=[nothing, input_dim])\n",
    "    \n",
    "    # hidden layer\n",
    "    h1 = nn.tanh(s*W1 + b1)\n",
    "    \n",
    "    # readout layer\n",
    "    readout = h1*W2 + b2\n",
    "\n",
    "    return s, readout, [W1, b1, W2, b2]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition frame_step(Any) in module Main at In[5]:3 overwritten at In[42]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "frame_step (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# closure\n",
    "function frame_step(action)\n",
    "    x_t, r_0, is_terminal = step!(env, action)\n",
    "    s_t = x_t #preprocess(x_t)\n",
    "    if is_terminal\n",
    "        reset(env)\n",
    "    end\n",
    "    s_t, r_0, is_terminal\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition unpack_memory(Any, Any) in module Main at In[6]:2 overwritten at In[23]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unpack_memory (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function unpack_memory(minibatch, BATCHSIZE)\n",
    "    s_j_batch = zeros(Float64, BATCHSIZE, STATE_DIMS)\n",
    "    a_batch = zeros(Int, BATCHSIZE)\n",
    "    r_batch = zeros(Float64, BATCHSIZE)\n",
    "    s_j1_batch = zeros(Float64, BATCHSIZE, STATE_DIMS)\n",
    "    \n",
    "    for i=1:BATCHSIZE\n",
    "        s_j_batch[i,:] = minibatch[i][1]\n",
    "        a_batch[i] = minibatch[i][2]\n",
    "        r_batch[i] = minibatch[i][3]\n",
    "        s_j1_batch[i,:] = minibatch[i][4]\n",
    "    end\n",
    "    s_j_batch, a_batch, r_batch, s_j1_batch\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition trainNetwork(Any, Any, Any, Any, Any, Any, Any, Any) in module Main at In[35]:6 overwritten at In[43]:4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainNetwork (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trainNetwork(frame_step, s, readout, wgts, s_target, readout_target, wgts_target, sess)\n",
    "    # one hot vector of the action taken\n",
    "    a = placeholder(Int32, shape=[nothing])\n",
    "    # scalar for r + gamma max_a' Q(s',a';theta_i^') from target\n",
    "    y = placeholder(Float32, shape=[nothing])\n",
    "    # dot product to get Q(s,a;theta_i) from main\n",
    "    readout_action = reduce_sum(readout.*one_hot(a, ACTIONS), reduction_indices=[2])\n",
    "    #readout_action = (readout.*one_hot(a, ACTIONS))*ones(Float32,ACTIONS)\n",
    "    # [ (r + gamma max_a' Q(s',a';theta_i^'))  -  Q(s,a;theta_i) ]^2\n",
    "    loss = reduce_mean((y - readout_action)^2) #, reduction_indices=[2])\n",
    "    # use adam update rule\n",
    "    train_step = train.minimize(train.AdamOptimizer(ALPHA), loss, var_list=wgts)\n",
    "\n",
    "    # store the previous observations in replay memory\n",
    "    D = ReplayMemory(REPLAY_MEM_SIZE)\n",
    "    \n",
    "    # initialize state\n",
    "    s_t, r_0, is_terminal = frame_step(0)\n",
    "\n",
    "    # must initialize tf vars before accessing\n",
    "    run(sess, initialize_all_variables())\n",
    "\n",
    "    # start training\n",
    "    epsilon = INITIAL_EPSILON\n",
    "    t = 0\n",
    "    while t < 1000\n",
    "       ## choose an action epsilon greedily\n",
    "        a_t = 0\n",
    "        if rand() <= epsilon || t <= OBSERVE\n",
    "            a_t = (rand(UInt) % ACTIONS)\n",
    "        else\n",
    "            # readout_t = [Q(s,a;theta_i) for all a in ACTIONS]\n",
    "            readout_t = run(sess, readout,  Dict(s=>s_t'))[1]    \n",
    "            a_t = indmax(readout_t)\n",
    "        end\n",
    "\n",
    "        # scale down epsilon\n",
    "        if epsilon > FINAL_EPSILON && t > OBSERVE\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "        end\n",
    "\n",
    "        # run same action K=1 times\n",
    "        for _=1:K\n",
    "            # run the selected action and observe next state and reward\n",
    "            s_t1, r_t, is_terminal = frame_step(a_t)\n",
    "\n",
    "            # store the transition in D\n",
    "            push_memory!(D, [s_t, a_t, r_t, s_t1, is_terminal])\n",
    "            \n",
    "            if is_terminal\n",
    "                s_t = INITIAL_STATE\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # only train if done observing\n",
    "        if t > 100 #OBSERVE\n",
    "            # sample a minibatch to train on\n",
    "            BATCHSIZE = 6\n",
    "            minibatch = sample(D, BATCHSIZE)\n",
    "            s_j_batch, a_batch, r_batch, s_j1_batch = unpack_memory(minibatch, BATCHSIZE)\n",
    "            \n",
    "            y_batch = Float64[]\n",
    "            # readout_j1_batch = [Q(s',a'; theta_i^') for all a in ACTIONS]\n",
    "            readout_j1_batch = run(sess, readout_target, Dict(s_target=>s_j1_batch))\n",
    "            for i=1:BATCHSIZE\n",
    "                # minibatch[i][5] = is_terminal, if is_terminal, only expect reward\n",
    "                if minibatch[i][5]\n",
    "                    push!(y_batch, r_batch[i])\n",
    "                # otherwise, need future reward from best action from current state\n",
    "                else\n",
    "                    push!(y_batch, r_batch[i] + GAMMA * max(readout_j1_batch[i]))\n",
    "                end\n",
    "            end\n",
    "\n",
    "            ## perform gradient step\n",
    "            dic = Dict(y=>y_batch, a=>a_batch, s=>s_j_batch)\n",
    "            \n",
    "            # run is where we compute [y - Q(s,a;theta_i)]^2 and do the update\n",
    "            run(sess, train_step, dic)\n",
    "            \n",
    "            # update target weights to match main weights\n",
    "            if t % TARGET_UPDATE_FREQ == 0\n",
    "                run(sess, [assign(vars[2], vars[1]) for vars=zip(wgts, wgts_target)])\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        t += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition runDQN(Any) in module Main at In[29]:2 overwritten at In[44]:2.\n",
      "WARNING: Method definition runDQN(Any, Any) in module Main at In[29]:2 overwritten at In[44]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "runDQN (generic function with 2 methods)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function runDQN(frame_step, k=0)\n",
    "    start_monitor(env, string(\"exp-\", env.name, \"_\", k));\n",
    "    reset(env) # reset the environment\n",
    "    # create tf session\n",
    "    sess = Session()\n",
    "    # training DQN\n",
    "    s, readout, wgts = createNetwork(ACTIONS, STATE_DIMS)\n",
    "    # check point DQN, only gets updated occassionally to preserve stability\n",
    "    s_target, readout_target, wgts_target = createNetwork(ACTIONS, STATE_DIMS)\n",
    "    trainNetwork(frame_step, s, readout, wgts, s_target, readout_target, wgts_target, sess)\n",
    "    close_monitor(env)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:55:22,677] Creating monitor directory exp-CartPole-v0_3\n",
      "[2016-11-28 02:55:22,681] Starting new video recorder writing to /home/carol/Documents/dqn_julia/exp-CartPole-v0_3/openaigym.video.3.26010.video000000.mp4\n",
      "[2016-11-28 02:55:34,251] Starting new video recorder writing to /home/carol/Documents/dqn_julia/exp-CartPole-v0_3/openaigym.video.3.26010.video000001.mp4\n",
      "[2016-11-28 02:55:35,755] Starting new video recorder writing to /home/carol/Documents/dqn_julia/exp-CartPole-v0_3/openaigym.video.3.26010.video000008.mp4\n",
      "[2016-11-28 02:55:40,130] Starting new video recorder writing to /home/carol/Documents/dqn_julia/exp-CartPole-v0_3/openaigym.video.3.26010.video000027.mp4\n",
      "[2016-11-28 02:55:46,208] Starting new video recorder writing to /home/carol/Documents/dqn_julia/exp-CartPole-v0_3/openaigym.video.3.26010.video000064.mp4\n",
      "[2016-11-28 02:55:48,939] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/carol/Documents/dqn_julia/exp-CartPole-v0_3')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runDQN(frame_step,k)\n",
    "k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
